{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natdebandi/hate_speech_ar/blob/main/3_GPT_evaluate_bin_finetunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmairhTcgdrz"
      },
      "source": [
        "# TP final - reconocimiento de discursos discriminatorios en Twitter\n",
        "\n",
        "## Validación del modelo GPT 3.5 con finetning binaro\n",
        "\n",
        "**Natalia Dedandi**\n",
        "\n",
        "model=\"gpt-3.5-turbo-0125\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La documentación de la API se encuentra aqui:\n",
        "\n",
        "https://platform.openai.com/docs/api-reference/introduction\n",
        "\n"
      ],
      "metadata": {
        "id": "SK58lmcuEE09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qGvz_HPEBx3",
        "outputId": "0a812180-1b0d-4c34-cfad-b10e15255fb4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.38.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.38.0-py3-none-any.whl (335 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.9/335.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.38.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "#seteo la KEY\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('openIA_key')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2wqMHCaUHS6v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZolEJGPsOpBd"
      },
      "outputs": [],
      "source": [
        "#creo el cliente OPENAI con mi usuario y proyecto\n",
        "client = OpenAI(\n",
        "  organization='org-1uHjwiaB3OlPzoxfVzhqOSzs',\n",
        "  project='proj_2fII7izwVGgYaERNNKhhMx4l',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recupero el modelo con finetuning binario\n",
        "\n",
        "model=\"gpt-3.5-turbo-0125\"\n",
        "\n",
        "Names model:\n",
        "ft:gpt-3.5-turbo-0125:personal:hate-speech-v2:9sJSTs9F\n",
        "\n"
      ],
      "metadata": {
        "id": "6Y66EA3iX9Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_bin=client.fine_tuning.jobs.retrieve('ftjob-RI7JuIvpL27w3XMLAIQWTNaw')"
      ],
      "metadata": {
        "id": "kvoE9u7LO52J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft_bin"
      ],
      "metadata": {
        "id": "V-1C6l_RQI2F",
        "outputId": "d1189e7f-1c3c-4a2f-bdc6-4e9f109be881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-RI7JuIvpL27w3XMLAIQWTNaw', created_at=1722722606, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:hate-speech-v2:9sJSTs9F', finished_at=1722731536, hyperparameters=Hyperparameters(n_epochs=3, batch_size=72, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-1uHjwiaB3OlPzoxfVzhqOSzs', result_files=['file-LrrG9erjq0phdN2C09yLtKCc'], seed=112634201, status='succeeded', trained_tokens=8146536, training_file='file-Mt9HMlQtIwmiVA8R0OF4aINw', validation_file='file-bBd2qAB8YmmZUUrnkXsVO9wF', estimated_finish=None, integrations=[], user_provided_suffix='hate_speech_v2')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0125:personal:hate-speech-v2:9sJSTs9F\",\n",
        "  messages=[\n",
        "    {'role': 'system', 'content': \"You are trained to analyze and detect the sentiment of the given text. Only hateful or not hateful is allowed. If the text is empty or is not clear answer not hateful\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hay que matarlos a todos\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "X02GVQynP5yo",
        "outputId": "9ac09659-1647-42b9-b798-6923d5517728",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='hateful', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#result_files=['file-LrrG9erjq0phdN2C09yLtKCc']\n",
        "\n",
        "content = client.files.content('file-LrrG9erjq0phdN2C09yLtKCc')"
      ],
      "metadata": {
        "id": "3sAjADteOpdL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "base64.b64decode(content.text.encode(\"utf-8\"))\n",
        "\n",
        "with open(\"result.csv\", \"wb\") as f:\n",
        "  f.write(base64.b64decode(content.text.encode(\"utf-8\")))"
      ],
      "metadata": {
        "id": "0xhsmQkXXD15"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics=compare_model_predictions(df_hateful['HATEFUL'],df_hateful['sentiment_bin'])"
      ],
      "metadata": {
        "id": "oDX-O6N_ceFS",
        "outputId": "76613ef2-da8e-4bd9-ae20-1ad359a511ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metrix\n",
            "{'Accuracy': 0.7756325487084546, 'Precision': 0.7820684033352095, 'Recall': 0.7756325487084546, 'f1': 0.7787565014472516}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}